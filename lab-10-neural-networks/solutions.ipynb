{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HLW_ib0Nvlwg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import keras\n",
        "from keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set, test_set = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfUvqkoGvsgs",
        "outputId": "ff7f060e-e235-421b-c8db-be933a1284eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = training_set\n",
        "X_test, y_test = test_set"
      ],
      "metadata": {
        "id": "KPO53scIvv3_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzQ4s8YZvzNR",
        "outputId": "1a7d9b2a-b283-4be9-def2-21366a74b3db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train, -1)\n",
        "X_test = np.expand_dims(X_test, -1)"
      ],
      "metadata": {
        "id": "yxrn5r8mv0vU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEb2u_IMv_gI",
        "outputId": "cf1d829c-90bf-4df5-fe1f-012c455050e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(np.float) / 255.0  \n",
        "X_test = X_test.astype(np.float) / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jneyKaqhwDp3",
        "outputId": "df922130-7e12-48e8-ce1d-40b093556099"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-4677e48edfd8>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_train = X_train.astype(np.float) / 255.0\n",
            "<ipython-input-7-4677e48edfd8>:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_test = X_test.astype(np.float) / 255.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "batch_size = 128\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "o9aIRH6AwG0q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=input_shape),\n",
        "            keras.layers.Flatten(),\n",
        "            layers.Dense(num_classes, activation=\"softmax\")\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "UEA-I8RCwKJs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Z8Q3AzwK-L",
        "outputId": "cf4daccd-2eda-4582-fb56-04ad15681141"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "8ANvKNtvwNvK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqgzEmeowZz9",
        "outputId": "163ee91e-ddb8-4fc8-940b-d67a884cf5c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 0.7515 - accuracy: 0.8150 - val_loss: 0.4074 - val_accuracy: 0.8986\n",
            "Epoch 2/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3899 - accuracy: 0.8964 - val_loss: 0.3353 - val_accuracy: 0.9087\n",
            "Epoch 3/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.9071 - val_loss: 0.3068 - val_accuracy: 0.9166\n",
            "Epoch 4/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3146 - accuracy: 0.9137 - val_loss: 0.2927 - val_accuracy: 0.9189\n",
            "Epoch 5/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.9168 - val_loss: 0.2835 - val_accuracy: 0.9217\n",
            "Epoch 6/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2907 - accuracy: 0.9192 - val_loss: 0.2788 - val_accuracy: 0.9216\n",
            "Epoch 7/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2837 - accuracy: 0.9206 - val_loss: 0.2745 - val_accuracy: 0.9254\n",
            "Epoch 8/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.9229 - val_loss: 0.2700 - val_accuracy: 0.9260\n",
            "Epoch 9/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.9229 - val_loss: 0.2695 - val_accuracy: 0.9253\n",
            "Epoch 10/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2697 - accuracy: 0.9250 - val_loss: 0.2692 - val_accuracy: 0.9277\n",
            "Epoch 11/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.9260 - val_loss: 0.2656 - val_accuracy: 0.9272\n",
            "Epoch 12/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2642 - accuracy: 0.9262 - val_loss: 0.2634 - val_accuracy: 0.9283\n",
            "Epoch 13/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.9269 - val_loss: 0.2621 - val_accuracy: 0.9282\n",
            "Epoch 14/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2594 - accuracy: 0.9273 - val_loss: 0.2630 - val_accuracy: 0.9278\n",
            "Epoch 15/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2578 - accuracy: 0.9278 - val_loss: 0.2606 - val_accuracy: 0.9299\n",
            "Epoch 16/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2556 - accuracy: 0.9287 - val_loss: 0.2607 - val_accuracy: 0.9301\n",
            "Epoch 17/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2544 - accuracy: 0.9292 - val_loss: 0.2597 - val_accuracy: 0.9302\n",
            "Epoch 18/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2528 - accuracy: 0.9298 - val_loss: 0.2599 - val_accuracy: 0.9298\n",
            "Epoch 19/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2513 - accuracy: 0.9295 - val_loss: 0.2599 - val_accuracy: 0.9306\n",
            "Epoch 20/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2500 - accuracy: 0.9307 - val_loss: 0.2599 - val_accuracy: 0.9303\n",
            "Epoch 21/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2496 - accuracy: 0.9309 - val_loss: 0.2585 - val_accuracy: 0.9310\n",
            "Epoch 22/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2480 - accuracy: 0.9309 - val_loss: 0.2597 - val_accuracy: 0.9306\n",
            "Epoch 23/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2472 - accuracy: 0.9312 - val_loss: 0.2597 - val_accuracy: 0.9302\n",
            "Epoch 24/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2462 - accuracy: 0.9311 - val_loss: 0.2586 - val_accuracy: 0.9312\n",
            "Epoch 25/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2453 - accuracy: 0.9317 - val_loss: 0.2602 - val_accuracy: 0.9293\n",
            "Epoch 26/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2445 - accuracy: 0.9319 - val_loss: 0.2587 - val_accuracy: 0.9307\n",
            "Epoch 27/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2438 - accuracy: 0.9322 - val_loss: 0.2598 - val_accuracy: 0.9299\n",
            "Epoch 28/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2428 - accuracy: 0.9327 - val_loss: 0.2581 - val_accuracy: 0.9316\n",
            "Epoch 29/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.9330 - val_loss: 0.2600 - val_accuracy: 0.9308\n",
            "Epoch 30/30\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2414 - accuracy: 0.9329 - val_loss: 0.2591 - val_accuracy: 0.9307\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c09d8f370>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probab = model.predict(X_test)\n",
        "y_pred = np.argmax(y_probab, axis=1)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0brFVHHzwlKX",
        "outputId": "c80aa6a8-c7ce-4e0c-af9e-a61d8ee59b74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96       980\n",
            "           1       0.97      0.98      0.97      1135\n",
            "           2       0.93      0.89      0.91      1032\n",
            "           3       0.89      0.92      0.90      1010\n",
            "           4       0.94      0.94      0.94       982\n",
            "           5       0.91      0.86      0.89       892\n",
            "           6       0.95      0.94      0.95       958\n",
            "           7       0.93      0.93      0.93      1028\n",
            "           8       0.87      0.90      0.88       974\n",
            "           9       0.91      0.91      0.91      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.93      0.93      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n",
            "[[ 965    0    1    2    0    5    4    2    1    0]\n",
            " [   0 1112    3    3    0    1    3    2   11    0]\n",
            " [   7   10  917   20    8    3   12   10   42    3]\n",
            " [   3    0   15  925    0   22    2   12   23    8]\n",
            " [   2    1    5    3  920    0    5    4   10   32]\n",
            " [   9    2    4   38    8  771   12    9   33    6]\n",
            " [  14    3   10    1    8   15  904    1    2    0]\n",
            " [   1    6   19   11    5    1    0  954    2   29]\n",
            " [   8    6    7   22    8   21    5   12  877    8]\n",
            " [  11    7    1   10   25    5    0   25    7  918]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=input_shape),\n",
        "            keras.layers.Flatten(),\n",
        "            layers.Dense(64, activation=\"tanh\"),\n",
        "            layers.Dense(128, activation=\"tanh\"),\n",
        "            layers.Dense(num_classes, activation=\"softmax\")\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "CADdjAqDwuAZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTo5VCXswwow",
        "outputId": "75532e41-3f93-430e-be5d-5ec5f42d2f2e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,850\n",
            "Trainable params: 59,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "GrJWhpDPwzIf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MAAwWofw0re",
        "outputId": "e3738a46-a6ff-4120-8fcb-52096c6579a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.4124 - accuracy: 0.8849 - val_loss: 0.2235 - val_accuracy: 0.9351\n",
            "Epoch 2/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1975 - accuracy: 0.9420 - val_loss: 0.1678 - val_accuracy: 0.9536\n",
            "Epoch 3/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1435 - accuracy: 0.9570 - val_loss: 0.1397 - val_accuracy: 0.9576\n",
            "Epoch 4/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1115 - accuracy: 0.9670 - val_loss: 0.1243 - val_accuracy: 0.9637\n",
            "Epoch 5/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0898 - accuracy: 0.9740 - val_loss: 0.1195 - val_accuracy: 0.9647\n",
            "Epoch 6/30\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0740 - accuracy: 0.9781 - val_loss: 0.1086 - val_accuracy: 0.9669\n",
            "Epoch 7/30\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0621 - accuracy: 0.9817 - val_loss: 0.1096 - val_accuracy: 0.9682\n",
            "Epoch 8/30\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0521 - accuracy: 0.9851 - val_loss: 0.1064 - val_accuracy: 0.9693\n",
            "Epoch 9/30\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.1104 - val_accuracy: 0.9697\n",
            "Epoch 10/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 0.1051 - val_accuracy: 0.9702\n",
            "Epoch 11/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.1126 - val_accuracy: 0.9702\n",
            "Epoch 12/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 0.1090 - val_accuracy: 0.9725\n",
            "Epoch 13/30\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.1169 - val_accuracy: 0.9709\n",
            "Epoch 14/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.1144 - val_accuracy: 0.9711\n",
            "Epoch 15/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 0.1186 - val_accuracy: 0.9709\n",
            "Epoch 16/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.1178 - val_accuracy: 0.9712\n",
            "Epoch 17/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.1186 - val_accuracy: 0.9727\n",
            "Epoch 18/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.1541 - val_accuracy: 0.9653\n",
            "Epoch 19/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.1346 - val_accuracy: 0.9697\n",
            "Epoch 20/30\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.1273 - val_accuracy: 0.9718\n",
            "Epoch 21/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.1576 - val_accuracy: 0.9675\n",
            "Epoch 22/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.1325 - val_accuracy: 0.9723\n",
            "Epoch 23/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1417 - val_accuracy: 0.9719\n",
            "Epoch 24/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.1460 - val_accuracy: 0.9714\n",
            "Epoch 25/30\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.1380 - val_accuracy: 0.9721\n",
            "Epoch 26/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.1548 - val_accuracy: 0.9703\n",
            "Epoch 27/30\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1428 - val_accuracy: 0.9737\n",
            "Epoch 28/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1390 - val_accuracy: 0.9735\n",
            "Epoch 29/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1398 - val_accuracy: 0.9737\n",
            "Epoch 30/30\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 5.5251e-04 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bfadd0d00>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probab = model.predict(X_test)\n",
        "y_pred = np.argmax(y_probab, axis=1)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGKtCqyew2Vw",
        "outputId": "54b57050-100f-4468-df95-755c829ff9e8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.96      0.97      0.97      1032\n",
            "           3       0.96      0.97      0.97      1010\n",
            "           4       0.98      0.97      0.98       982\n",
            "           5       0.97      0.96      0.97       892\n",
            "           6       0.98      0.97      0.98       958\n",
            "           7       0.97      0.97      0.97      1028\n",
            "           8       0.97      0.97      0.97       974\n",
            "           9       0.98      0.97      0.97      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n",
            "[[ 969    0    2    1    0    2    3    2    1    0]\n",
            " [   0 1123    4    2    0    1    1    2    2    0]\n",
            " [   6    1 1000    3    1    2    3    7    9    0]\n",
            " [   1    0    8  983    0    4    0    6    6    2]\n",
            " [   1    1    5    1  952    1    4    3    1   13]\n",
            " [   2    0    2   10    1  860    8    3    5    1]\n",
            " [   7    2    3    1    3    7  932    0    3    0]\n",
            " [   1    3    9    7    2    1    0  997    1    7]\n",
            " [   1    0    4    6    4    5    2    6  944    2]\n",
            " [   4    2    0    7    5    4    0    7    2  978]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=input_shape),\n",
        "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(num_classes, activation=\"softmax\"),\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "YymrhTF9xQKj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhl3bppzxS2k",
        "outputId": "1c75c65e-c080-4f60-ea57-035f8c60a5ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "nccCljqwxUyL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnGfY80cxW_Z",
        "outputId": "58affabd-e285-44f8-ce54-cd885b550314"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "375/375 [==============================] - 44s 115ms/step - loss: 0.3880 - accuracy: 0.8864 - val_loss: 0.1034 - val_accuracy: 0.9721\n",
            "Epoch 2/30\n",
            "375/375 [==============================] - 45s 121ms/step - loss: 0.1205 - accuracy: 0.9626 - val_loss: 0.0709 - val_accuracy: 0.9793\n",
            "Epoch 3/30\n",
            "375/375 [==============================] - 44s 116ms/step - loss: 0.0922 - accuracy: 0.9711 - val_loss: 0.0596 - val_accuracy: 0.9822\n",
            "Epoch 4/30\n",
            "375/375 [==============================] - 45s 119ms/step - loss: 0.0737 - accuracy: 0.9766 - val_loss: 0.0505 - val_accuracy: 0.9853\n",
            "Epoch 5/30\n",
            "375/375 [==============================] - 44s 118ms/step - loss: 0.0658 - accuracy: 0.9792 - val_loss: 0.0464 - val_accuracy: 0.9867\n",
            "Epoch 6/30\n",
            "375/375 [==============================] - 43s 114ms/step - loss: 0.0588 - accuracy: 0.9815 - val_loss: 0.0421 - val_accuracy: 0.9876\n",
            "Epoch 7/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0527 - accuracy: 0.9836 - val_loss: 0.0404 - val_accuracy: 0.9888\n",
            "Epoch 8/30\n",
            "375/375 [==============================] - 43s 116ms/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.0426 - val_accuracy: 0.9876\n",
            "Epoch 9/30\n",
            "375/375 [==============================] - 44s 117ms/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 0.0391 - val_accuracy: 0.9893\n",
            "Epoch 10/30\n",
            "375/375 [==============================] - 44s 116ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 0.0344 - val_accuracy: 0.9904\n",
            "Epoch 11/30\n",
            "375/375 [==============================] - 45s 119ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 0.0350 - val_accuracy: 0.9897\n",
            "Epoch 12/30\n",
            "375/375 [==============================] - 44s 118ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.0352 - val_accuracy: 0.9902\n",
            "Epoch 13/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 0.0359 - val_accuracy: 0.9893\n",
            "Epoch 14/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 0.0337 - val_accuracy: 0.9902\n",
            "Epoch 15/30\n",
            "375/375 [==============================] - 47s 125ms/step - loss: 0.0340 - accuracy: 0.9888 - val_loss: 0.0347 - val_accuracy: 0.9909\n",
            "Epoch 16/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.0329 - val_accuracy: 0.9911\n",
            "Epoch 17/30\n",
            "375/375 [==============================] - 44s 118ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.0315 - val_accuracy: 0.9911\n",
            "Epoch 18/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 0.0325 - val_accuracy: 0.9909\n",
            "Epoch 19/30\n",
            "375/375 [==============================] - 45s 119ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.0314 - val_accuracy: 0.9918\n",
            "Epoch 20/30\n",
            "375/375 [==============================] - 45s 119ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.0312 - val_accuracy: 0.9916\n",
            "Epoch 21/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 0.0296 - val_accuracy: 0.9926\n",
            "Epoch 22/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0306 - val_accuracy: 0.9922\n",
            "Epoch 23/30\n",
            "375/375 [==============================] - 44s 119ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0311 - val_accuracy: 0.9913\n",
            "Epoch 24/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0306 - val_accuracy: 0.9920\n",
            "Epoch 25/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.0298 - val_accuracy: 0.9922\n",
            "Epoch 26/30\n",
            "375/375 [==============================] - 47s 126ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0295 - val_accuracy: 0.9917\n",
            "Epoch 27/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.0296 - val_accuracy: 0.9919\n",
            "Epoch 28/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.0320 - val_accuracy: 0.9923\n",
            "Epoch 29/30\n",
            "375/375 [==============================] - 46s 123ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 0.0321 - val_accuracy: 0.9916\n",
            "Epoch 30/30\n",
            "375/375 [==============================] - 43s 115ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.0304 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bfb685960>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probab = model.predict(X_test)\n",
        "y_pred = np.argmax(y_probab, axis=1)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GihS43kmxYpb",
        "outputId": "dcfe8d87-433d-4b1f-c9f6-f9ee68086ae9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       1.00      1.00      1.00      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.99      1.00      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       1.00      0.99      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       0.99      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "[[ 977    1    0    0    0    0    0    1    1    0]\n",
            " [   0 1132    3    0    0    0    0    0    0    0]\n",
            " [   1    0 1023    0    1    0    0    6    1    0]\n",
            " [   0    0    2 1005    0    2    0    0    1    0]\n",
            " [   0    0    0    0  977    0    0    1    0    4]\n",
            " [   0    0    0    4    0  887    1    0    0    0]\n",
            " [   2    2    1    0    1    3  948    0    1    0]\n",
            " [   0    2    6    1    0    0    0 1018    1    0]\n",
            " [   4    0    1    2    0    1    0    2  960    4]\n",
            " [   0    0    0    0    3    4    0    3    1  998]]\n"
          ]
        }
      ]
    }
  ]
}